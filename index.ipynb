{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Saving Frat Parties, One Bop at a Time</center>\n",
    "<center>Aleem Virani</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Introduction</center>\n",
    "Fraternity parties: a staple of the modern college experience. Every college student seems to have this shared experience, no matter what college they go to. On television, these parties were protrayed as an unforgettable experience with DJs playing hit after hit, students dancing on tables, and everybody similing and having a good time. However, after conducting my own research as well as talking with some of my more \"outgoing\" friends, this wasn't the case. Sure people do have a good time, but the good times are short lived. Columbia student, Huber Gonzalez, documented <a href = https://www.columbiaspectator.com/spectrum/2016/09/22/your-first-frat-party-play-play-timeline-if-youve-never-been-frat-party-its-time/>his experience</a> at party in Columbia. In his words, the \"turn-up\" started at 12:04 am and was quickly followed by the \"realization\" at 12:43 am where, according to Gonzalez, \"...the frat's completely out of booze, the music starts to suck, and everyone's ready to bounce the f*** outta there.\" In 40 minutes, the \"party\" is seemingly over. Assuming an average song length of around 3 minutes, the party ended after 13 songs. If things don't change fast, the phrase \"Party All Night\" will be as revelant to the next generation as the fax machine is to this generation, and who better to lead this change than a third year Computer Science nerd with asthma. In this project, I take a look at what audio features make up party songs using the Spotify API and Spotipy, as well as create a classification model to help people pick out good songs to play at a party."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4D-4MsbIXrZy"
   },
   "source": [
    "## <center>Setup</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we need to import and install multiple libraries: <a href = https://spotipy.readthedocs.io/en/2.21.0/>Spotipy</a>, <a href = https://pandas.pydata.org/pandas-docs/stable/>Pandas</a>, <a href = https://seaborn.pydata.org/>Seaborn</a>, \n",
    "<a href = https://docs.scipy.org/doc/numpy/user/>Numpy</a>, <a href = http://scikit-learn.org/stable/documentation.html>Scikit-learn</a>, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "id": "JagqWvKstn7D"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install spotipy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "id": "mselbvlfuVS3"
   },
   "outputs": [],
   "source": [
    "#Used to interact with Spotify API\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#Used for classification\n",
    "from xgboost import XGBClassifier\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaiFhaD0a174"
   },
   "source": [
    "Now that we have our tools, the next thing we have to do is be able to make calls to the Spotify API through Spotipy. To do this, we need a client id and a client secret key. Both of these can be obtained by registering an app through the <a href = https://developer.spotify.com/dashboard/login>Spotify for Developers</a> portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Spotipy object to make Spotify API calls\n",
    "auth_manager = SpotifyClientCredentials(client_id='client id',client_secret='client secret')\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we that we have a Spotipy object, we can start to collect our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOjk67pTfuPo"
   },
   "source": [
    "## <center>Data Collection</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of this process is to obtain songs that would play at a fraternity party. To get the songs, I simply searched \"Fraternity Playlists\" on the Spotify Web Player and stored the playlists IDs in a List. From this, I used the Spotipy object to get the name of each song and stored this, along with the song ID into a Data Frame. I also added a column \"Frat\" and filled it all with 1s to indicate that these are good songs to play at a party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "id": "wfs7WbNXd6jF"
   },
   "outputs": [],
   "source": [
    "frat_playlists = ['12mcHHoTRZF6cAxfjAvMPP', '3Gd67DHBoA9QRSYk2hhHdq', '2KfDfNcRVrNVYgU46eJYcJ', '2mmdzFwPVURPPeWSG2Gadh', '08SEeX1N03RuaRAmKhin8F', '1ea6YoJmz0eaKzIxjW5PPQ', '1RQ3vAw4gEmLeJE96faCVc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "id": "2OaB2VCvej60"
   },
   "outputs": [],
   "source": [
    "songs = []\n",
    "#Collect the IDs of all the songs present in these playlists and store them in an array\n",
    "for p in frat_playlists:\n",
    "    x = sp.playlist_tracks(p)\n",
    "    for i in range(0,len(x['items'])):\n",
    "        songs.append(x['items'][i]['track']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTD_fQ4IiJOA",
    "outputId": "f73e0fc5-44f2-4142-bde0-b2bac713122b"
   },
   "outputs": [],
   "source": [
    "#Got rid of all duplicate IDs by transforming the list to a set and back\n",
    "songs = list(set(songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "id": "RJ9pp4wNbPwB"
   },
   "outputs": [],
   "source": [
    "#Create empty DataFrame\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hb0g9nCmbdYE"
   },
   "outputs": [],
   "source": [
    "#Get the title of each of these songs and add them to the Data Frame\n",
    "title = []\n",
    "for i in songs:\n",
    "    t = sp.track(i)\n",
    "    title.append(t['name'])\n",
    "#Add the ID and title of the tracks to the Data Frame\n",
    "df['ID'] = songs\n",
    "df['Title'] = title\n",
    "#Mark each of these entries as 1 to indicate that these are good party songs and add to the Data Frame\n",
    "df['Frat'] = [1] * len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step of this process was to get the audio features of each of the songs present within the Data Frame and add it to said Data Frame. This is an important step as these features will end up helping when determing whether a song is good for a party or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through each of the rows in the DF and get the danceability, energy, loudness, speechiness, \n",
    "#acousticness, instrumentalness, liveness, valence, and tempo of each song\n",
    "danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo = [],[],[],[],[],[],[],[],[]\n",
    "for index, row in df.iterrows():\n",
    "    #Make a central call to the Spotipy API to get the audio features of each track\n",
    "    info = sp.audio_features(tracks = [df.loc[index, 'ID']])[0]\n",
    "    danceability.append(info['danceability'])\n",
    "    energy.append(info['energy'])\n",
    "    loudness.append(info['loudness'])\n",
    "    speechiness.append(info['speechiness'])\n",
    "    acousticness.append(info['acousticness'])\n",
    "    instrumentalness.append(info['instrumentalness'])\n",
    "    liveness.append(info['liveness'])\n",
    "    valence.append(info['valence'])\n",
    "    tempo.append(info['tempo'])\n",
    "\n",
    "#Add these metrics to the Data Frame\n",
    "df['danceability'] = danceability\n",
    "df['energy'] = energy\n",
    "df['loudness'] = loudness\n",
    "df['speechiness'] = speechiness\n",
    "df['acousticness'] = acousticness\n",
    "df['instrumentalness'] = instrumentalness\n",
    "df['liveness'] = liveness\n",
    "df['valence'] = valence\n",
    "df['tempo'] = tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "s8-RyqBJdP8q",
    "outputId": "17053c42-2958-4f22-8a35-d33396eb2961"
   },
   "outputs": [],
   "source": [
    "#Output party song Data Frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created a Data Frame for songs that would be good to play at a frat party, it's to do the same thing for songs that would be __bad__ to play at a frat party. Besides figuring out how how Spotipy worked, this was the hardest part of the project. What would constitute as a bad song? I ended up crowdsourcing some answers found that \"bad\" songs include songs written by Taylor Swift, sad songs, slow songs, songs written by Olivia Rodrigo, country songs, and Kids Bop. As I did before, I created a new Data Frame that incorporates these selections and filled it with the song ID, the song name, an indicator that showed these songs were not meant for a party, and the audio features of each track. The one step in the process that differed with the previous Data Frame creation was the fact that I got rid of tracks that were considered to be \"bad\" if they were also in the \"good\" list of songs. This was to make sure that each song only belonged to the \"good\" section or the \"bad\" section and not both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5Ga8h39dRq-"
   },
   "outputs": [],
   "source": [
    "bad_music = ['5ksaUaYEgnywCzO6nmAIwN', '6duuzFPn741MPpmaurNbH1', '37i9dQZF1EQmPV0vrce2QZ', '37i9dQZF1DWWEJlAGA9gs0', '4kStQdar45aPq6v97qT2Dc', '3a6Rd7GxLcl6ZCSfy2B0oL', '1Tsa6hKcC2TIJ6ZcbsEhNx', '37i9dQZF1DZ06evO0WqnZe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjJllCYsjwtX"
   },
   "outputs": [],
   "source": [
    "bad_songs = []\n",
    "#Collect the IDs of all the songs present in these playlists and store them in an array\n",
    "for p in bad_music:\n",
    "    x = sp.playlist_tracks(p)\n",
    "    for i in range(0,len(x['items'])):\n",
    "        bad_songs.append(x['items'][i]['track']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NTrlBWjj8DD"
   },
   "outputs": [],
   "source": [
    "#If a bad song also appears as a good song, delete it from the bad_songs array \n",
    "for i in bad_songs:\n",
    "    if i in songs:\n",
    "        index = bad_songs.index(i)\n",
    "        bad_songs.pop(index)\n",
    "#Got rid of all duplicate IDs by transforming the list to a set and back\n",
    "bad_songs = list(set(bad_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlIM9X83kiAO"
   },
   "outputs": [],
   "source": [
    "#Create a Bad Data Frame for bad songs to play at a party \n",
    "bdf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODPWUjhplAso"
   },
   "outputs": [],
   "source": [
    "#Get the title of each of these songs and add them to the Bad Data Frame\n",
    "bad_title = []\n",
    "for i in bad_songs:\n",
    "    t = sp.track(i)\n",
    "    bad_title.append(t['name'])\n",
    "#Add the ID and title of the tracks to the Bad Data Frame\n",
    "bdf['ID'] = bad_songs \n",
    "bdf['Title'] = bad_title\n",
    "#Mark each of these entries as 0 to indicate that these are bad party songs and add to the Bad Data Frame\n",
    "bdf['Frat'] = [0]*len(bdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad Data Frame\n",
    "bdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through each of the rows in the Bad DF and get the danceability, energy, loudness, speechiness, \n",
    "#acousticness, instrumentalness, liveness, valence, and tempo of each song\n",
    "danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo = [],[],[],[],[],[],[],[],[]\n",
    "for index, row in bdf.iterrows():\n",
    "    #Make a central call to the Spotipy API to get the audio features of each track\n",
    "    info = sp.audio_features(tracks = [bdf.loc[index, 'ID']])[0]\n",
    "    danceability.append(info['danceability'])\n",
    "    energy.append(info['energy'])\n",
    "    loudness.append(info['loudness'])\n",
    "    speechiness.append(info['speechiness'])\n",
    "    acousticness.append(info['acousticness'])\n",
    "    instrumentalness.append(info['instrumentalness'])\n",
    "    liveness.append(info['liveness'])\n",
    "    valence.append(info['valence'])\n",
    "    tempo.append(info['tempo'])\n",
    "#Add these metrics to the Bad Data Frame\n",
    "bdf['danceability'] = danceability\n",
    "bdf['energy'] = energy\n",
    "bdf['loudness'] = loudness\n",
    "bdf['speechiness'] = speechiness\n",
    "bdf['acousticness'] = acousticness\n",
    "bdf['instrumentalness'] = instrumentalness\n",
    "bdf['liveness'] = liveness\n",
    "bdf['valence'] = valence\n",
    "bdf['tempo'] = tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our two Data Frames, it's time to combine them into one main Data Frame so we can start with our data exploration stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Br1Gbjf8lEBO"
   },
   "outputs": [],
   "source": [
    "#Good df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "jddcHUQEl5ie",
    "outputId": "ebf5bf5e-f9dc-4029-9aec-bf84ab0215b3"
   },
   "outputs": [],
   "source": [
    "#Bad df\n",
    "bdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7hbrmAIze3E"
   },
   "outputs": [],
   "source": [
    "#Combine dfs\n",
    "df = df.append(bdf).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combined df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Data Exploration</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, I wanted to go over the audio features of the songs found within the Data Frame. The first thing I wanted to know was if certain features were more influential than others when determining if a song is good for a party. To do this, I decided to create a correlation matrix and heatmap of the correlation matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap of correlation matrix\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix of df\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To me, a strong correlation is anything above 40%. Based on this, the attributes that have the most impact on the classification of a song are __\"danceability\"__, __\"energy\"__, __\"loudness\"__, __\"speechiness\"__, and __\"acousticness\"__. With this in mind, lets look at the distribution of these attributes across the fraternity songs and non-fraternity songs within our Data Frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sns.histplot(data = df, x = 'danceability', hue = 'Frat').set(title = 'Histogram of Danceability of Songs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main thing I saw in the histogram above was the the danceability of both frat songs and non-frat songs are left-skewed. However, it seems that, on average, danceability of frat songs are higher than that of non-frat songs. Overall it seems that while both classes of songs are danceable, you would find more poeple dancing to a frat song.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sns.histplot(data = df, x = 'energy', hue = 'Frat').set(title = 'Histogram of Energy of Songs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this histogram, it seems that the energy of frat songs are left skewed, while the energy of non-frat songs are slightly right skewed. This means that the energy of non-frat songs would be on the lower end, while frat songs would have higher energy. This doesn't surprise me as the whole reason why people play frat songs in a party is to get people active and moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sns.histplot(data = df, x = 'loudness', hue = 'Frat').set(title = 'Histogram of Loudness of Songs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, non-frat songs are left skewed while frat songs and normally distributed. Based on this, it seems like there is high variance in the loudness of a non-frat songs as the values range from -40 to -4 while frat songs range from -12 to 0. Lastly, it seems that frat songs tend to be more loud than non-frat songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sns.histplot(data = df, x = 'speechiness', hue = 'Frat').set(title = 'Histogram of Speechiness of Songs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this histogram, it's clear that non-frats songs are right skewed and not speechy at all. This is in stark contrast to frat songs which are also right skewed, but have high volatility as the speechiness varies between 0.04-0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sns.histplot(data = df, x = 'acousticness', hue = 'Frat').set(title = 'Histogram of Acousticness of Songs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly in this histogram, non-frat songs seem to be bimodal while frat songs are unimodal and skewed to the right. This tells me that the acoustics of frat songs tend to be on the lower end, while the acoustics of non-frat songs tend to either be very low or very high. From this data exploration, we now know that fraternity songs tend to be loud, high in energy, somewhat speechy, danceable, and have very little acoustic presence. I was surprised that tempo wasn't a factor in this classification, as I thought that faster songs would be more favorable at parties, but I guess that this is not the case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKdDPry_ZKNd"
   },
   "source": [
    "## <center>Song Classification</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've taken a look at what factors influence the classification of a song the most, the question still begs: \"Can we come up with a way to determine what songs are good to play at parties?\" The answer, of course, is yes, with the help of a classification model. The first step in this process is to create a train-test split for the data. Here, I decided to not use every attribute that we collected earlier, but rather the 5 attributes that we found to be most impactful when deciding if a song is good to play at a frat party.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRKlKwdX2t1Q"
   },
   "outputs": [],
   "source": [
    "#Target is the frat column\n",
    "y = df['Frat']\n",
    "#Classify on 'danceability', 'energy', 'loudness', 'speechiness', and'acousticness'\n",
    "X = df[['danceability', 'energy', 'loudness', 'speechiness','acousticness']]\n",
    "#Use 20% of the data to test and the rest to train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in the process is to train a model with this data. However, I had no idea which model would be best in this scenario. To solve this, I decided to use LazyClassifier to run a bunch of different classificatiion models and pick the best one to use on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "id": "Zq-TduOtYRd1",
    "outputId": "7f6903e2-4703-4b88-c242-74748dd8e8f1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create and deploy LazyClassifier model\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top three models that the LazyClassifier displayed was GaussianNB, NearestCentroid, SGDClassifier, and SVC. The accuracies of these models were 0.87, 0.86, 0.87, and 0.87 respectively. This is good, but I wanted to see if by using all the data to classify, I would get better accuracy results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target is the frat column\n",
    "y = df['Frat']\n",
    "#Use all the Spotify attributes to classify a song\n",
    "X = df.drop(['Title', 'ID', 'Frat'], axis = 1)\n",
    "#Use 20% of the data to test and the rest to train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and deploy LazyClassifier model\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that by using all the data, the results do improve. In this case, the top models to use were SVC, NuSVC, LinearSVC, and RandomForestClassifier with the accuracies being 0.9, 0.89, 0.89, and 0.89 respectively. Another way to potentially increase the results of the classification was to standardize the data. The general formula I used was to subract the mean from the column from each value in the column and divide it by the standard deviation of the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each column, subtract the mean from each value in the column and divide it by the standard \n",
    "#deviation of the column.\n",
    "df['danceability'] = (df['danceability']-df['danceability'].mean())/df['danceability'].std()\n",
    "df['energy'] = (df['energy']-df['energy'].mean())/df['energy'].std()\n",
    "df['loudness'] = (df['loudness']-df['loudness'].mean())/df['loudness'].std()\n",
    "df['speechiness'] = (df['speechiness']-df['speechiness'].mean())/df['speechiness'].std()\n",
    "df['acousticness'] = (df['acousticness']-df['acousticness'].mean())/df['acousticness'].std()\n",
    "df['instrumentalness'] = (df['instrumentalness']-df['instrumentalness'].mean())/df['instrumentalness'].std()\n",
    "df['liveness'] = (df['liveness']-df['liveness'].mean())/df['liveness'].std()\n",
    "df['valence'] = (df['valence']-df['valence'].mean())/df['valence'].std()\n",
    "df['tempo'] = (df['tempo']-df['tempo'].mean())/df['tempo'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardized DF\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have standardized the data, let's repeat the steps above see whether or not the models have improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target is the frat column\n",
    "y = df['Frat']\n",
    "#Classify on 'danceability', 'energy', 'loudness', 'speechiness', and'acousticness'\n",
    "X = df[['danceability', 'energy', 'loudness', 'speechiness','acousticness']]\n",
    "#Use 20% of the data to test and the rest to train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and deploy LazyClassifier model\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target is the frat column\n",
    "y = df['Frat']\n",
    "#Use all the Spotify attributes to classify a song\n",
    "X = df.drop(['Title', 'ID', 'Frat'], axis = 1)\n",
    "#Use 20% of the data to test and the rest to train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and deploy LazyClassifier model\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the classifiers themselves and the scores of the classifiers haven't changed at all, thus making me come to the concluion that normalizing the data didn't really matter. Again, the models in which every attribute was used tended to yield better results. \n",
    "\n",
    "Although these models yielded great results, the key metric that I really care about here is precision, as I want to find what proportion of predicted frat songs was actually correct. I decided to take the top 4 models that yielded the best results in the classification above and measure the precision of each of them.\n",
    "\n",
    "The first model I tested was NuSVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create and test NuSVC model\n",
    "clf = make_pipeline(StandardScaler(), NuSVC())\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "precision_score(y_test, y_predict, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the precision score of this model was 89.03%.\n",
    "\n",
    "The next model I tested was Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and test RandomForestClassifier model\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "precision_score(y_test, y_predict, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, the precision score of this model was 89.03%.\n",
    "\n",
    "The next model I tested was SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and test SVC model\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "precision_score(y_test, y_predict, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the precision score of this model was 89.87%: a significant jump from the previous model.\n",
    "\n",
    "The last model I checked was LinearSVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and test LinearSVC model\n",
    "clf = make_pipeline(StandardScaler(),LinearSVC())\n",
    "clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "precision_score(y_test, y_predict, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the precision score of this model was 89.03%\n",
    "\n",
    "Overall, it seems that the best model to use here is <a href = https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC>SVC</a>, as it has the highest percision out of all the models tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Conclusion</center>\n",
    "It turns out that making, let alone making a hit song, is a lot deeper than people expect it to be. Before this project, I had no idea about the metrics that Spotify stores for each song. However, with the use of these metrics, we were able to not only identify defining characteristics of popular party songs, but we were able to use this information and more to create a model that can help DJs and hosts everywhere curate playlists to ensure the satisfaction of partygoers all over the world. Although the approach of this project was to determine good songs to play at a party, the project is robust enough for you to curate it to your personal needs such as trying to make a playlist for a friend or finding songs that match your current mood. The next step, if any for this project, is to find ways to increase the precision and accuracy of these models and eventually refine it enough so that they can replace a human altogether. I would also love to test the validity of my model by curating a playlist for a party and playing it for an actual crowd. Overall, I hope that this was worth the read and you were able to learn something that you didn't know earlier."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
